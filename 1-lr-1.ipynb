{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "----Data statistics------'\n",
      "#Edges 8504267\n",
      "#Classes 10\n",
      "#Train samples 1000\n",
      "#Val samples 0\n",
      "#Test samples 10000\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 118.00 MiB (GPU 0; 15.75 GiB total capacity; 119.52 MiB already allocated; 18.88 MiB free; 492.50 KiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-381f98f99a1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test accuracy {:.2%}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-381f98f99a1a>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, features, labels, mask)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/LR-combine1/gcn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/dgl/nn/pytorch/conv/graphconv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, graph, feat, weight)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mshp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 118.00 MiB (GPU 0; 15.75 GiB total capacity; 119.52 MiB already allocated; 18.88 MiB free; 492.50 KiB cached)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch.nn.functional as F\n",
    "# Torch\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# Torchvison\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import CIFAR100, CIFAR10\n",
    "\n",
    "# Utils\n",
    "import visdom\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Custom\n",
    "import models.resnet as resnet\n",
    "import models.lossnet as lossnet\n",
    "from config import *\n",
    "from data.sampler import SubsetSequentialSampler\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "import arguments\n",
    "from utils import *\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from scipy import sparse\n",
    "from dgl import DGLGraph\n",
    "from dgl.data import register_data_args, load_data\n",
    "\n",
    "from gcn import GCN\n",
    "from vat import VATLoss\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "random.seed(\"CVPR21\")\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "# alpha = 0.1\n",
    "# beta = 0.033\n",
    "accuracies = []\n",
    "\n",
    "##\n",
    "# Data\n",
    "train_transform = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomCrop(size=32, padding=4),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010]) # T.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)) # CIFAR-100\n",
    "])\n",
    "\n",
    "test_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010]) # T.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)) # CIFAR-100\n",
    "])\n",
    "cifar10_test  = CIFAR10('./cifar10', train=False, download=True, transform=test_transform)\n",
    "cifar10_train = CIFAR10('./cifar10', train=True, download=True, transform=train_transform)\n",
    "\n",
    "class CIFAR10_re(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.cifar10 = CIFAR10(root=path,\n",
    "                                        download=True,\n",
    "                                        train=True,\n",
    "                                        transform=test_transform)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if isinstance(index, np.float64):\n",
    "            index = index.astype(np.int64)\n",
    "\n",
    "        data, target = self.cifar10[index]\n",
    "\n",
    "        return data, target, index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cifar10)\n",
    "\n",
    "cifar10_unlabeled   = CIFAR10_re('./cifar10')\n",
    "\n",
    "def evaluate(model, features, labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)\n",
    "vis = None\n",
    "plot_data = {'X': [], 'Y': [], 'legend': ['Backbone Loss', 'Module Loss', 'Total Loss']}\n",
    "\n",
    "trial = 0\n",
    "\n",
    "all_indices = set(np.arange(NUM_TRAIN))\n",
    "val_indices = random.sample(all_indices, 0)\n",
    "all_indices = np.setdiff1d(list(all_indices), val_indices)\n",
    "\n",
    "file2 = open(\"./init_indice.pkl\", 'rb')\n",
    "initial_indices = pickle.load(file2)\n",
    "\n",
    "# initial_indices = random.sample(list(all_indices), ADDENDUM)\n",
    "# f = open(\"./init_indice.pkl\", 'rb')\n",
    "# pickle.dump(initial_indices, f)\n",
    "# indices = all_indices\n",
    "# random.shuffle(indices)\n",
    "# labeled_set = indices[:ADDENDUM]\n",
    "\n",
    "# unlabeled_set = indices[ADDENDUM:]\n",
    "\n",
    "# current_indices = list(initial_indices)\n",
    "\n",
    "train_loader = DataLoader(cifar10_train, batch_size=BATCH, \n",
    "                          sampler=SubsetRandomSampler(initial_indices), \n",
    "                          pin_memory=True)\n",
    "test_loader  = DataLoader(cifar10_test, batch_size=BATCH)\n",
    "val_loader = DataLoader(cifar10_train, batch_size=BATCH, \n",
    "                          sampler=SubsetRandomSampler(val_indices), \n",
    "                          pin_memory=True)\n",
    "dataloaders  = {'train': train_loader, 'test': test_loader, 'val': val_loader}\n",
    "\n",
    "# Model\n",
    "# resnet18    = resnet.ResNet18(num_classes=10).cuda()\n",
    "# # loss_module = lossnet.LossNet().cuda()\n",
    "# models      = {'backbone': resnet18}\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def train_epoch(models, criterion, optimizers, dataloaders, epoch, epoch_loss, vis=None, plot_data=None):\n",
    "    models['backbone'].train()\n",
    "    # models['module'].train()\n",
    "    global iters\n",
    "\n",
    "    for data in tqdm(dataloaders['train'], leave=False, total=len(dataloaders['train'])):\n",
    "        inputs = data[0].cuda()\n",
    "        labels = data[1].cuda()\n",
    "        # print(inputs.shape, labels.shape)\n",
    "#         iters += 1\n",
    "\n",
    "        optimizers['backbone'].zero_grad()\n",
    "        # optimizers['module'].zero_grad()\n",
    "\n",
    "        scores, features, for_gcn = models['backbone'](inputs)\n",
    "        target_loss = criterion(scores, labels)\n",
    "\n",
    "\n",
    "        target_loss.backward()\n",
    "        optimizers['backbone'].step()\n",
    "        # optimizers['module'].step()\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "def test(models, dataloaders, mode='val'):\n",
    "    assert mode == 'val' or mode == 'test'\n",
    "    models['backbone'].eval()\n",
    "    # models['module'].eval()\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for (inputs, labels) in dataloaders[mode]:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            scores, _, _ = models['backbone'](inputs)\n",
    "            _, preds = torch.max(scores.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "    \n",
    "    return 100 * correct / total\n",
    "\n",
    "#\n",
    "def train(models, criterion, optimizers, schedulers, dataloaders, num_epochs, epoch_loss, vis, plot_data, cycle, accuracies):\n",
    "#     print('>> Train a Model.')\n",
    "    best_acc = 0.\n",
    "    checkpoint_dir = os.path.join('./cifar10', 'train', 'weights')\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        schedulers['backbone'].step()\n",
    "        # schedulers['module'].step()\n",
    "\n",
    "        train_epoch(models, criterion, optimizers, dataloaders, epoch, epoch_loss, vis, plot_data)\n",
    "#         print(accuracies, epoch)\n",
    "\n",
    "file = open(\"./graph0.pkl\", 'rb')\n",
    "graph = pickle.load(file)\n",
    "file1 = open(\"./vector0.pkl\", 'rb')\n",
    "data_graph = pickle.load(file1)\n",
    "file2 = open(\"./label0.pkl\", 'rb')\n",
    "labels = pickle.load(file2)\n",
    "file2 = open(\"./cur_indice0.pkl\", 'rb')\n",
    "current_indices = pickle.load(file2)\n",
    "\n",
    "labels = torch.LongTensor(labels)\n",
    "\n",
    "pos_train = len(current_indices)\n",
    "mask = np.zeros(data_graph.shape[0])\n",
    "mask[np.arange(pos_train)] = 1\n",
    "mask = np.array(mask, dtype=np.bool)\n",
    "train_mask = mask\n",
    "# print(train_mask.shape)\n",
    "mask = np.zeros(data_graph.shape[0])\n",
    "# mask[np.arange(pos_train, pos_train+5000)] = 1\n",
    "mask = np.array(mask, dtype=np.bool)\n",
    "val_mask = mask\n",
    "mask = np.zeros(data_graph.shape[0])\n",
    "mask[np.arange(50000, 60000)] = 1\n",
    "mask = np.array(mask, dtype=np.bool)\n",
    "test_mask = mask\n",
    "features = torch.FloatTensor(data_graph)\n",
    "\n",
    "if hasattr(torch, 'BoolTensor'):\n",
    "    train_mask = torch.BoolTensor(train_mask)\n",
    "    val_mask = torch.BoolTensor(val_mask)\n",
    "    test_mask = torch.BoolTensor(test_mask)\n",
    "else:\n",
    "    train_mask = torch.ByteTensor(train_mask)\n",
    "    val_mask = torch.ByteTensor(val_mask)\n",
    "    test_mask = torch.ByteTensor(test_mask)\n",
    "\n",
    "in_feats = features.shape[1]\n",
    "n_classes = 10\n",
    "graph = nx.from_scipy_sparse_matrix(graph)\n",
    "n_edges = graph.number_of_edges()\n",
    "print(\"\"\"----Data statistics------'\n",
    "#Edges %d\n",
    "#Classes %d\n",
    "#Train samples %d\n",
    "#Val samples %d\n",
    "#Test samples %d\"\"\" %\n",
    "    (n_edges, n_classes,\n",
    "        train_mask.int().sum().item(),\n",
    "        val_mask.int().sum().item(),\n",
    "        test_mask.int().sum().item()))\n",
    "\n",
    "cuda = True\n",
    "# torch.cuda.set_device(args.gpu)\n",
    "features = features.cuda()\n",
    "labels = labels.cuda()\n",
    "train_mask = train_mask.cuda()\n",
    "val_mask = val_mask.cuda()\n",
    "test_mask = test_mask.cuda()    \n",
    "\n",
    "\n",
    "# graph preprocess and calculate normalization factor\n",
    "g = graph\n",
    "# add self loop\n",
    "if True:\n",
    "    g.remove_edges_from(nx.selfloop_edges(g))\n",
    "    g.add_edges_from(zip(g.nodes(), g.nodes()))\n",
    "g = DGLGraph(g)\n",
    "n_edges = g.number_of_edges()\n",
    "# normalization\n",
    "degs = g.in_degrees().float()\n",
    "norm = torch.pow(degs, -0.5)\n",
    "norm[torch.isinf(norm)] = 0\n",
    "if cuda:\n",
    "    norm = norm.cuda()\n",
    "g.ndata['norm'] = norm.unsqueeze(1)\n",
    "\n",
    "# create GCN model\n",
    "model = GCN(g,\n",
    "            in_feats,\n",
    "            50,\n",
    "            n_classes,\n",
    "            1,\n",
    "            F.relu,\n",
    "            0.1)\n",
    "\n",
    "model.load_state_dict(torch.load(\"model_gcn\" + str(0) + \".pt\"))\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "# loss_fcn = torch.nn.CrossEntropyLoss()\n",
    "# vat_loss = VATLoss(xi=args.xi, eps=args.eps, ip=args.ip)\n",
    "\n",
    "\n",
    "\n",
    "print()\n",
    "acc = evaluate(model, features, labels, test_mask)\n",
    "print(\"Test accuracy {:.2%}\".format(acc))\n",
    "accuracies.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
